{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation\n",
    "\n",
    "We will take a first-pass at evaluating or technique to start understanding its efficacy. We will existing CNN architectures and evaluate its performance on our interested categories with and without using our interested categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Copied from clustering NB\n",
    "def load_metadata(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return [x.strip().split('\\t') for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE=(64,64,3)\n",
    "\n",
    "def get_mobilenet(input_shape=INPUT_SHAPE):\n",
    "    application = tf.keras.applications.MobileNet(input_shape=input_shape, include_top=False)\n",
    "    for i in range(len(application.layers)):\n",
    "        application.layers[i].trainable = i < 10\n",
    "    return tf.keras.Sequential([\n",
    "        application,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(200, activation='softmax'),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simplecnn(input_shape=INPUT_SHAPE):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(512, (3,3), (1,1), input_shape=input_shape, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(512, (2,2), (1,1), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(256, (2,2), (1,1), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(256, (2,2), (1,1), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(512),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(256),\n",
    "        tf.keras.layers.Dense(200),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplecnn = get_simplecnn()\n",
    "# simplecnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dennis/miniconda3/envs/tf-gpu/lib/python3.7/site-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Model)   (None, 2, 2, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               13000     \n",
      "=================================================================\n",
      "Total params: 3,381,320\n",
      "Trainable params: 155,912\n",
      "Non-trainable params: 3,225,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobilenet = get_mobilenet()\n",
    "mobilenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def decode_img(image):\n",
    "    img = tf.image.decode_jpeg(image, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return tf.image.resize(img, [64, 64])\n",
    "\n",
    "@tf.function\n",
    "def load_image_data(path, label):\n",
    "    img_data = tf.io.read_file(path)\n",
    "    img = decode_img(img_data)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(metadata):\n",
    "    labels = np.array([x[1] for x in metadata])\n",
    "    distinct_labels = np.array([[x] for x in set(labels)])\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    encoder.fit(distinct_labels)\n",
    "    y_train = encoder.transform([[x] for x in labels])\n",
    "#     y_train = np.array([x[1] for x in np.argwhere(y_train == 1)])\n",
    "    return (y_train, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into memory...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Remove hardcoding\n",
    "print('Loading data into memory...')\n",
    "train_metadata = load_metadata('./metadata_output/train_metadata.txt')\n",
    "(y_train, encoder) = load_labels(train_metadata)\n",
    "\n",
    "# Interested indices for test data filtering\n",
    "interested_categories = ['n01882714', 'n04562935']\n",
    "interested_one_hot = encoder.transform([[x] for x in interested_categories])\n",
    "interested_indices = np.array([x[1] for x in np.argwhere(interested_one_hot == 1)])\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding sanity checks;\n",
    "# assert(len(train_metadata) == len(y_train))\n",
    "# assert(len(set(y_train)) == 200)\n",
    "assert(np.count_nonzero(y_train == 1) == len(train_metadata))\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation sets\n",
    "paths_and_labels = [(train_metadata[x][0], y_train[x]) for x in range(len(y_train))]\n",
    "np.random.shuffle(paths_and_labels)\n",
    "num_valid = int(len(paths_and_labels) * 0.1)\n",
    "valid_path_and_labels = paths_and_labels[:num_valid]\n",
    "train_path_and_labels = paths_and_labels[num_valid:]\n",
    "\n",
    "# Convert into a TF dataset\n",
    "list_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: train_path_and_labels,\n",
    "    (tf.string, tf.int32),\n",
    "    (tf.TensorShape([]), tf.TensorShape([len(y_train[0])]))\n",
    ")\n",
    "list_ds = list_ds.map(lambda x,y: load_image_data(x, y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "list_ds = list_ds.cache()\n",
    "list_ds = list_ds.repeat()\n",
    "list_ds = list_ds.batch(30)\n",
    "list_ds = list_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: valid_path_and_labels,\n",
    "    (tf.string, tf.int32),\n",
    "    (tf.TensorShape([]), tf.TensorShape([len(y_train[0])]))\n",
    ")\n",
    "valid_ds = valid_ds.map(lambda x,y: load_image_data(x, y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_ds = valid_ds.cache()\n",
    "valid_ds = valid_ds.repeat()\n",
    "valid_ds = valid_ds.batch(30)\n",
    "valid_ds = valid_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Shouldn't be hardcoded.\n",
    "TRAIN_STEPS=3000\n",
    "TEST_STEPS=500\n",
    "NUM_EPOCHS=250\n",
    "TEST_TRAIN_SPLIT=0.33\n",
    "def train_model(model, dataset, valid_dataset, name):    \n",
    "    # Compile model                                                                                                      \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=1e-3),                                                           \n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),                                  \n",
    "                  metrics=['accuracy'])      \n",
    "    \n",
    "    # Stop early if we're not making good progress                                                                           \n",
    "    early_stop_monitor = tf.keras.callbacks.EarlyStopping(                                                                   \n",
    "        monitor='val_loss',                                                                                              \n",
    "        restore_best_weights=True,                                                                                       \n",
    "        patience=10)   \n",
    "\n",
    "    # Prepare for checkpoints            \n",
    "    checkpoint_path = './checkpoints/' + name + '/cp-{epoch:04d}.ckpt'                                   \n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(                                                                    \n",
    "        filepath=checkpoint_path,                                                                                    \n",
    "        verbose=1,                                                                                                   \n",
    "        save_weights_only=False,                                                                                     \n",
    "        save_freq=25000000)\n",
    "\n",
    "    # Tensorboard                                                                                                        \n",
    "    log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")                                              \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    history = model.fit(                                                                                                 \n",
    "        x=dataset,\n",
    "        epochs=NUM_EPOCHS,                                                                                                  \n",
    "        steps_per_epoch=TRAIN_STEPS,\n",
    "        callbacks=[tensorboard_callback, cp_callback, early_stop_monitor],\n",
    "        use_multiprocessing=True,\n",
    "        validation_steps=num_valid,\n",
    "        validation_data=valid_dataset,\n",
    "        shuffle=True)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on interesting inputs\n",
    "def evaluate_model(model, test_sets):\n",
    "    for test_set in test_sets:\n",
    "        X = test_set[0]\n",
    "        y = test_set[1]\n",
    "        model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 3000 steps, validate for 7000 steps\n",
      "Epoch 1/250\n",
      "   1/3000 [..............................] - ETA: 3:20:51 - loss: 5.2990 - accuracy: 0.0000e+00WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.149067). Check your callbacks.\n",
      "3000/3000 [==============================] - 194s 65ms/step - loss: 5.2507 - accuracy: 0.0583 - val_loss: 5.2228 - val_accuracy: 0.0884\n",
      "Epoch 2/250\n",
      "3000/3000 [==============================] - 186s 62ms/step - loss: 5.2151 - accuracy: 0.0931 - val_loss: 5.2081 - val_accuracy: 0.1001\n",
      "Epoch 3/250\n",
      "3000/3000 [==============================] - 187s 62ms/step - loss: 5.1952 - accuracy: 0.1127 - val_loss: 5.1986 - val_accuracy: 0.1090\n",
      "Epoch 4/250\n",
      "3000/3000 [==============================] - 189s 63ms/step - loss: 5.1860 - accuracy: 0.1216 - val_loss: 5.2005 - val_accuracy: 0.1054\n",
      "Epoch 5/250\n",
      "3000/3000 [==============================] - 188s 63ms/step - loss: 5.1787 - accuracy: 0.1287 - val_loss: 5.1915 - val_accuracy: 0.1161\n",
      "Epoch 6/250\n",
      "3000/3000 [==============================] - 190s 63ms/step - loss: 5.1711 - accuracy: 0.1363 - val_loss: 5.1956 - val_accuracy: 0.1117\n",
      "Epoch 7/250\n",
      "3000/3000 [==============================] - 189s 63ms/step - loss: 5.1646 - accuracy: 0.1427 - val_loss: 5.1891 - val_accuracy: 0.1189\n",
      "Epoch 8/250\n",
      "3000/3000 [==============================] - 189s 63ms/step - loss: 5.1534 - accuracy: 0.1540 - val_loss: 5.2016 - val_accuracy: 0.1053\n",
      "Epoch 9/250\n",
      "3000/3000 [==============================] - 189s 63ms/step - loss: 5.1526 - accuracy: 0.1546 - val_loss: 5.1933 - val_accuracy: 0.1139\n",
      "Epoch 10/250\n",
      "3000/3000 [==============================] - 189s 63ms/step - loss: 5.1429 - accuracy: 0.1645 - val_loss: 5.1962 - val_accuracy: 0.1117\n",
      "Epoch 11/250\n",
      "3000/3000 [==============================] - 189s 63ms/step - loss: 5.1387 - accuracy: 0.1689 - val_loss: 5.1807 - val_accuracy: 0.1266\n",
      "Epoch 12/250\n",
      "3000/3000 [==============================] - 190s 63ms/step - loss: 5.1322 - accuracy: 0.1751 - val_loss: 5.1760 - val_accuracy: 0.1306\n",
      "Epoch 13/250\n",
      "3000/3000 [==============================] - 189s 63ms/step - loss: 5.1268 - accuracy: 0.1805 - val_loss: 5.1712 - val_accuracy: 0.1361\n",
      "Epoch 14/250\n",
      "3000/3000 [==============================] - 189s 63ms/step - loss: 5.1251 - accuracy: 0.1823 - val_loss: 5.1761 - val_accuracy: 0.1316\n",
      "Epoch 15/250\n",
      "3000/3000 [==============================] - 189s 63ms/step - loss: 5.1182 - accuracy: 0.1893 - val_loss: 5.1780 - val_accuracy: 0.1290\n",
      "Epoch 16/250\n",
      "3000/3000 [==============================] - 190s 63ms/step - loss: 5.1168 - accuracy: 0.1905 - val_loss: 5.1839 - val_accuracy: 0.1234\n",
      "Epoch 17/250\n",
      "3000/3000 [==============================] - 190s 63ms/step - loss: 5.1119 - accuracy: 0.1954 - val_loss: 5.1755 - val_accuracy: 0.1326\n",
      "Epoch 18/250\n",
      "3000/3000 [==============================] - 190s 63ms/step - loss: 5.1104 - accuracy: 0.1968 - val_loss: 5.1636 - val_accuracy: 0.1436\n",
      "Epoch 19/250\n",
      "3000/3000 [==============================] - 190s 63ms/step - loss: 5.1041 - accuracy: 0.2034 - val_loss: 5.1698 - val_accuracy: 0.1377\n",
      "Epoch 20/250\n",
      "3000/3000 [==============================] - 190s 63ms/step - loss: 5.1030 - accuracy: 0.2043 - val_loss: 5.1650 - val_accuracy: 0.1419\n",
      "Epoch 21/250\n",
      "3000/3000 [==============================] - 189s 63ms/step - loss: 5.1003 - accuracy: 0.2073 - val_loss: 5.1734 - val_accuracy: 0.1327\n",
      "Epoch 22/250\n",
      "3000/3000 [==============================] - 189s 63ms/step - loss: 5.0944 - accuracy: 0.2131 - val_loss: 5.1640 - val_accuracy: 0.1423\n",
      "Epoch 23/250\n",
      "3000/3000 [==============================] - 189s 63ms/step - loss: 5.0959 - accuracy: 0.2111 - val_loss: 5.1676 - val_accuracy: 0.1399\n",
      "Epoch 24/250\n",
      "3000/3000 [==============================] - 189s 63ms/step - loss: 5.0899 - accuracy: 0.2176 - val_loss: 5.1767 - val_accuracy: 0.1299\n",
      "Epoch 25/250\n",
      "3000/3000 [==============================] - 190s 63ms/step - loss: 5.0898 - accuracy: 0.2177 - val_loss: 5.1688 - val_accuracy: 0.1383\n",
      "Epoch 26/250\n",
      "3000/3000 [==============================] - 190s 63ms/step - loss: 5.0879 - accuracy: 0.2197 - val_loss: 5.1660 - val_accuracy: 0.1407\n",
      "Epoch 27/250\n",
      "3000/3000 [==============================] - 190s 63ms/step - loss: 5.0868 - accuracy: 0.2207 - val_loss: 5.1706 - val_accuracy: 0.1361\n",
      "Epoch 28/250\n",
      "3000/3000 [==============================] - 190s 63ms/step - loss: 5.0833 - accuracy: 0.2240 - val_loss: 5.1697 - val_accuracy: 0.1373\n",
      "WARNING:tensorflow:From /home/dennis/miniconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "ename": "PermissionDeniedError",
     "evalue": "/models; Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f4afc3628d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train and save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmobilenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mobilenet_imbalanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmobilenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/models/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mobilenet_imbalanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model saved'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    973\u001b[0m     \"\"\"\n\u001b[1;32m    974\u001b[0m     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m--> 975\u001b[0;31m                       signatures, options)\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 115\u001b[0;31m                           signatures, options)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;31m# default learning phase placeholder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0msave_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    897\u001b[0m   \u001b[0;31m# the checkpoint, copy assets into the assets directory, and write out the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m   \u001b[0;31m# SavedModel proto itself.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m   \u001b[0mutils_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_variables_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m   \u001b[0mobject_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m   builder_impl.copy_assets_to_destination_dir(asset_info.asset_filename_map,\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/saved_model/utils_impl.py\u001b[0m in \u001b[0;36mget_or_create_variables_dir\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[0mvariables_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_variables_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvariables_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir\u001b[0;34m(dirname)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m   \u001b[0mrecursive_create_dir_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m   \"\"\"\n\u001b[0;32m--> 453\u001b[0;31m   \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: /models; Permission denied"
     ]
    }
   ],
   "source": [
    "# Train and save model\n",
    "train_model(mobilenet, list_ds, valid_ds, 'mobilenet_imbalanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/mobilenet_imbalanced/assets\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "mobilenet.save(\"./models/{}\".format('mobilenet_imbalanced'))\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load test data, filter for interest, evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-TF-GPU",
   "language": "python",
   "name": "conda-tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
